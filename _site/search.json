[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Susmi Sharma",
    "section": "",
    "text": "I am a doctoral student studying Developmental Language Disorder from the computational modeling prospective. I will populate this website with various projects in computational models."
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "Susmi Sharma",
    "section": "Interests:",
    "text": "Interests:\n\nSupervised Computational Modeling\nUnsupervised Computational Modeling\nIdentifying the vital characteristics of the Developmental Language Disorder.\nOther child developmental disorders\n\n\nContact me at:\n[sxs220550@utdallas.edu]"
  },
  {
    "objectID": "ProjectCode.html",
    "href": "ProjectCode.html",
    "title": "All Code——Random forest model",
    "section": "",
    "text": "Pre-processing data\n\nInstalling necessary packages\n\n# install.packages(setdiff(c(\"randomForest\", \"ggplot2\", \"caret\",\"cowplot\", \"rfUtilities\", \n#                            \"writexl\"), rownames(installed.packages())))\n#install.packages(\"writexl\")\nlibrary(randomForest)\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\nlibrary(caret)\n\nLoading required package: ggplot2\n\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:randomForest':\n\n    margin\n\n\nLoading required package: lattice\n\nlibrary(cowplot)\nlibrary(rpart)\nlibrary(\"dplyr\")\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked from 'package:randomForest':\n\n    combine\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(\"writexl\")\n\n\n\nLoading the dataset\n\nHeart_data &lt;- read.csv(\"CVD_cleaned.csv\")\nhead(Heart_data)\n\n  General_Health                 Checkup Exercise Heart_Disease Skin_Cancer\n1           Poor Within the past 2 years       No            No          No\n2      Very Good    Within the past year       No           Yes          No\n3      Very Good    Within the past year      Yes            No          No\n4           Poor    Within the past year      Yes           Yes          No\n5           Good    Within the past year       No            No          No\n6           Good    Within the past year       No            No          No\n  Other_Cancer Depression Diabetes Arthritis    Sex Age_Category Height_.cm.\n1           No         No       No       Yes Female        70-74         150\n2           No         No      Yes        No Female        70-74         165\n3           No         No      Yes        No Female        60-64         163\n4           No         No      Yes        No   Male        75-79         180\n5           No         No       No        No   Male          80+         191\n6           No        Yes       No       Yes   Male        60-64         183\n  Weight_.kg.   BMI Smoking_History Alcohol_Consumption Fruit_Consumption\n1       32.66 14.54             Yes                   0                30\n2       77.11 28.29              No                   0                30\n3       88.45 33.47              No                   4                12\n4       93.44 28.73              No                   0                30\n5       88.45 24.37             Yes                   0                 8\n6      154.22 46.11              No                   0                12\n  Green_Vegetables_Consumption FriedPotato_Consumption\n1                           16                      12\n2                            0                       4\n3                            3                      16\n4                           30                       8\n5                            4                       0\n6                           12                      12\n\n\n\n\nSelecting a subset of participants from CVD: 20000 participants\n\nNumber_ofparticipants &lt;- 10000\n## This is a very large dataset, let's only select 10000 samples from both groups\nset.seed(150)\nYes_case &lt;- sample(which(Heart_data$Heart_Disease == \"Yes\"), Number_ofparticipants)\nset.seed(150)\nNo_case &lt;- sample(which(Heart_data$Heart_Disease == \"No\"), Number_ofparticipants)\nData_yes &lt;- Heart_data[Yes_case, ]\nData_no &lt;-  Heart_data[No_case, ]\nData_total &lt;- rbind(Data_yes, Data_no)\nhead(Data_total)\n\n       General_Health              Checkup Exercise Heart_Disease Skin_Cancer\n43289            Poor Within the past year      Yes           Yes         Yes\n281436           Fair Within the past year      Yes           Yes          No\n196610           Fair Within the past year      Yes           Yes          No\n306903           Fair Within the past year       No           Yes          No\n304887           Poor Within the past year       No           Yes          No\n278988           Fair Within the past year      Yes           Yes          No\n       Other_Cancer Depression Diabetes Arthritis    Sex Age_Category\n43289            No         No      Yes       Yes   Male        65-69\n281436           No         No      Yes       Yes   Male        70-74\n196610           No         No      Yes       Yes Female        40-44\n306903          Yes         No      Yes       Yes Female        55-59\n304887           No        Yes       No       Yes   Male          80+\n278988           No         No       No        No   Male        50-54\n       Height_.cm. Weight_.kg.   BMI Smoking_History Alcohol_Consumption\n43289          175      102.97 33.52             Yes                   0\n281436         170      104.33 36.02             Yes                   0\n196610         180      136.08 41.84             Yes                   5\n306903         160       65.77 25.69              No                   0\n304887         155       62.60 26.07             Yes                   0\n278988         180      106.59 32.78              No                  25\n       Fruit_Consumption Green_Vegetables_Consumption FriedPotato_Consumption\n43289                 12                           16                       3\n281436                60                           30                       4\n196610                60                            2                      12\n306903                12                           12                       3\n304887                28                           28                       4\n278988                 3                            4                       8\n\n\n\n\nConverting Age from range to numerical value\n\n## We will convert the Age variable that is in range form in the dataset to a numerical form.\nMy_Age_Heart_Data &lt;- data.frame(Data_total$Age_Category, Data_total$Heart_Disease)\nnames(My_Age_Heart_Data) &lt;- c(\"Age_Category\", \"Heart_Disease\") \n\n#  This code gets the data in the right format\nMy_Age_Heart_Data$Age_min &lt;- \n  as.numeric(substr(My_Age_Heart_Data$Age_Category, start = 1, stop = 2))\nMy_Age_Heart_Data$Age_max &lt;- \n  as.numeric(substr(My_Age_Heart_Data$Age_Category, start = 4, stop = 5))\nfor (i in 1:Number_ofparticipants){\n  # if (is.na(My_Age_Heart_Data$Age_min[i])){\n  #   My_Age_Heart_Data$Age_min[i] = My_Age_Heart_Data$Age_max[i]}\n  if (is.na(My_Age_Heart_Data$Age_max[i])){\n    My_Age_Heart_Data$Age_max[i] = My_Age_Heart_Data$Age_min[i]}\n}\n## We check if there were other missing age value included in the data.\nmore_missing_agevalue &lt;- Data_total$Age_Category[(is.na(My_Age_Heart_Data$Age_max))]\n\n## Since all the missing values were participants 80 and older, we replace those missing values with 80.\nMy_Age_Heart_Data$Age_max[(is.na(My_Age_Heart_Data$Age_max))] = as.numeric(80)\n# This code gives me the final age value to be used in the analysis.\nMy_Age_Heart_Data$FinalAge &lt;- \n  (My_Age_Heart_Data$Age_min + My_Age_Heart_Data$Age_max)/2\nhead(My_Age_Heart_Data)\n\n  Age_Category Heart_Disease Age_min Age_max FinalAge\n1        65-69           Yes      65      69       67\n2        70-74           Yes      70      74       72\n3        40-44           Yes      40      44       42\n4        55-59           Yes      55      59       57\n5          80+           Yes      80      80       80\n6        50-54           Yes      50      54       52\n\n## Adding cleaned Age data in the data\nData_total$FinalAge &lt;- My_Age_Heart_Data$FinalAge\nsum(is.na(Data_total$FinalAge))\n\n[1] 0\n\n\n\n\nConverting the variables that are in character form to factors\n\nData_total$Diabetes &lt;- factor(Data_total$Diabetes)\nData_total$Checkup &lt;- factor(Data_total$Checkup)\nData_total$General_Health &lt;- factor(Data_total$General_Health)\nData_total$Arthritis &lt;- factor(Data_total$Arthritis)\nData_total$Sex &lt;- factor(Data_total$Sex)\nData_total$Smoking_History &lt;- factor(Data_total$Smoking_History)\nData_total$Height_.cm. &lt;- as.numeric(Data_total$Height_.cm.)\nData_total$Skin_Cancer &lt;- factor(Data_total$Skin_Cancer)\nData_total$Other_Cancer &lt;- factor(Data_total$Other_Cancer)\nData_total$Exercise &lt;- factor(Data_total$Exercise)\nData_total$Depression &lt;- factor(Data_total$Depression)\n\n\n\nFinal Pre-processed data\n\n## Here we will remove the Diabetes column that do not make sense to us. \nExtra_DiabetesandnullAge_Column &lt;- \n  which((Data_total$Diabetes == \"Yes, but female told only during pregnancy\") | \n          (Data_total$Diabetes == \"No, pre-diabetes or borderline diabetes\"))\n\n## This is our final data with clean variables\nData_total &lt;- Data_total[-Extra_DiabetesandnullAge_Column, ]\nData_total$Diabetes &lt;- factor(Data_total$Diabetes)\nData_total$Age_Category &lt;- NULL # removing age category\nstr(Data_total)\n\n'data.frame':   19323 obs. of  19 variables:\n $ General_Health              : Factor w/ 5 levels \"Excellent\",\"Fair\",..: 4 2 2 2 4 2 5 3 5 2 ...\n $ Checkup                     : Factor w/ 5 levels \"5 or more years ago\",..: 5 5 5 5 5 5 5 5 5 5 ...\n $ Exercise                    : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 1 1 2 2 2 2 2 ...\n $ Heart_Disease               : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Skin_Cancer                 : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 1 1 1 1 1 1 1 ...\n $ Other_Cancer                : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 1 1 1 1 1 ...\n $ Depression                  : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 1 2 1 1 1 ...\n $ Diabetes                    : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 1 1 2 1 1 ...\n $ Arthritis                   : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 1 2 2 2 1 ...\n $ Sex                         : Factor w/ 2 levels \"Female\",\"Male\": 2 2 1 1 2 2 2 2 1 1 ...\n $ Height_.cm.                 : num  175 170 180 160 155 180 185 163 163 173 ...\n $ Weight_.kg.                 : num  103 104.3 136.1 65.8 62.6 ...\n $ BMI                         : num  33.5 36 41.8 25.7 26.1 ...\n $ Smoking_History             : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 1 2 1 2 1 1 2 ...\n $ Alcohol_Consumption         : num  0 0 5 0 0 25 1 2 1 2 ...\n $ Fruit_Consumption           : num  12 60 60 12 28 3 4 30 12 16 ...\n $ Green_Vegetables_Consumption: num  16 30 2 12 28 4 10 8 12 2 ...\n $ FriedPotato_Consumption     : num  3 4 12 3 4 8 12 3 4 12 ...\n $ FinalAge                    : num  67 72 42 57 80 52 67 72 77 62 ...\n\n\n\n\nDependent variable vs independent variable of the model\n\n## independent Variables\nInputtoHeartDisease_Model2 &lt;- \n  data.frame(Data_total$Fruit_Consumption, Data_total$Alcohol_Consumption,\n  Data_total$Green_Vegetables_Consumption, Data_total$FriedPotato_Consumption,\n  Data_total$FinalAge, Data_total$BMI, Data_total$Diabetes,\n  Data_total$Checkup, Data_total$General_Health, Data_total$Arthritis,\n  Data_total$Sex, Data_total$Smoking_History, Data_total$Height_.cm.,\n  Data_total$Weight_.kg.,Data_total$Skin_Cancer, Data_total$Other_Cancer, \n  Data_total$Exercise, Data_total$Depression)\nnames(InputtoHeartDisease_Model2) &lt;- \n  c(\"Fruit\", \"Alcohol\", \"GreenVeggie\", \"FriedPotato\",\n    \"FinalAge\", \"BMI\", \"Diabetes\", \"Checkup\", \"GeneralHealth\", \n    \"Arthritis\", \"Sex\", \"SmokingHistory\", \"Height_.cm\", \n    \"Weight_.kg.\",\"SkinCancer\", \"OtherCancer\", \"Exercise\", \"Depression\")\n\n## Dependent Variable\nHeart_label &lt;- as.factor(Data_total$Heart_Disease)\n\n\n\nPartitioning of the data into training/testing for random forest model\n\nset.seed(222)\nsample_data &lt;- sample(nrow(InputtoHeartDisease_Model2), .7* nrow(InputtoHeartDisease_Model2))\ntrain_data &lt;- InputtoHeartDisease_Model2[sample_data, ]\ntest_data &lt;- InputtoHeartDisease_Model2[-sample_data, ]\nHeartLabel_Train &lt;- Heart_label[sample_data]\nHeartLabel_Test &lt;- Heart_label[-sample_data]\n\n\n\n\nRunning the model\n\nThis is our random forest model with all features\n\nour_model_500 &lt;- randomForest(HeartLabel_Train ~ ., data = train_data, ntree = 500, \n                              proximity = T, mtry = 3)\nour_model_500\n\n\nCall:\n randomForest(formula = HeartLabel_Train ~ ., data = train_data,      ntree = 500, proximity = T, mtry = 3) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n        OOB estimate of  error rate: 24.44%\nConfusion matrix:\n      No  Yes class.error\nNo  4775 1973   0.2923829\nYes 1333 5445   0.1966657\n\n\n\n\nParameter Tuning\n\n## Parameter Tuning A: here we find the optimal number of decision trees\nplot(our_model_500, log = \"y\", main = \"All-features: Error rate as a function \n     of  ntrees (= 500)\", lwd = 3, bty = \"n\", ylim = c(0.2,0.8))\nlegend(\"top\", colnames(our_model_500$err.rate), col = 1:3, cex = 0.8, fill = 1:3)\n\n\n\n## This is our random forest model with all features\nour_model_1000 &lt;- randomForest(HeartLabel_Train ~ ., data = train_data, ntree = 1000, \n                              proximity = T, mtry = 3)\nour_model_1000\n\n\nCall:\n randomForest(formula = HeartLabel_Train ~ ., data = train_data,      ntree = 1000, proximity = T, mtry = 3) \n               Type of random forest: classification\n                     Number of trees: 1000\nNo. of variables tried at each split: 3\n\n        OOB estimate of  error rate: 24.35%\nConfusion matrix:\n      No  Yes class.error\nNo  4786 1962   0.2907528\nYes 1332 5446   0.1965181\n\nplot(our_model_1000, log = \"y\", main = \"All-features: Error rate as a function \n     of  ntrees (= 1000)\", lwd = 3, bty = \"n\", ylim = c(0.2,0.8))\nlegend(\"top\", colnames(our_model_1000$err.rate), col = 1:3, cex = 0.8, fill = 1:3)\n\n\n\n## Parameter Tuning B: now we will find the optimal number of split of the tree\noob_values &lt;- vector(length = 10)\nfor (i in 1:10) {\n  Num_model &lt;- randomForest(HeartLabel_Train ~ ., data = train_data, mtry = i, ntree = 500)\n  oob_values[i] &lt;- Num_model$err.rate[nrow(Num_model$err.rate), 1]\n}\nplot(oob_values, main = \"Error rate as a function of Num of Nodes\", lwd = 3, bty = \"n\",\n     ylim = c(0.2,0.8), col = 2, xlab = \"Nodes\", ylab = \"OOB Rate\")\n\n\n\n\n\n\nWe will record the out of bag error estimate of the optimal model\n\nour_model_500 &lt;- randomForest(HeartLabel_Train ~ ., data = train_data, ntree = 500, \n                              proximity = T, mtry = 2)\nour_model_500\n\n\nCall:\n randomForest(formula = HeartLabel_Train ~ ., data = train_data,      ntree = 500, proximity = T, mtry = 2) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 24.43%\nConfusion matrix:\n      No  Yes class.error\nNo  4726 2022   0.2996443\nYes 1282 5496   0.1891413\n\n\n\n\n\nModel Features and Performance\n\nModel Performance on the testing and training set\n\n## Testing the model accuracy on the training data\ntrain_rf &lt;- predict(our_model_500, train_data)\nTrain_Summary &lt;- confusionMatrix(train_rf, HeartLabel_Train)\nTrain_Summary\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   No  Yes\n       No  6091  384\n       Yes  657 6394\n                                          \n               Accuracy : 0.923           \n                 95% CI : (0.9184, 0.9275)\n    No Information Rate : 0.5011          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.8461          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9026          \n            Specificity : 0.9433          \n         Pos Pred Value : 0.9407          \n         Neg Pred Value : 0.9068          \n             Prevalence : 0.4989          \n         Detection Rate : 0.4503          \n   Detection Prevalence : 0.4787          \n      Balanced Accuracy : 0.9230          \n                                          \n       'Positive' Class : No              \n                                          \n\n## Testing the model accuracy on the testing data\ntest_rf &lt;- predict(our_model_500, test_data)\nTest_Summary &lt;- confusionMatrix(test_rf, HeartLabel_Test)\nTest_Summary ## All features\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   No  Yes\n       No  2022  541\n       Yes  904 2330\n                                          \n               Accuracy : 0.7507          \n                 95% CI : (0.7394, 0.7618)\n    No Information Rate : 0.5047          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.502           \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.6910          \n            Specificity : 0.8116          \n         Pos Pred Value : 0.7889          \n         Neg Pred Value : 0.7205          \n             Prevalence : 0.5047          \n         Detection Rate : 0.3488          \n   Detection Prevalence : 0.4421          \n      Balanced Accuracy : 0.7513          \n                                          \n       'Positive' Class : No              \n                                          \n\n\n\n\nWhich variables are most important according to our model\n\n#install.packages(\"ggalt\")\nsuppressPackageStartupMessages({\n  library(ggalt)\n  library(randomForest)\n  library(data.table)\n})\n\n## Here we get a nice looking plot for the feature important index\nimp &lt;- data.table(importance(our_model_500), keep.rownames = TRUE)\nimp = arrange(imp, MeanDecreaseGini)\nimp[, rn := factor(rn, unique(rn))]\nggplot(melt(imp, id.vars=\"rn\")[grep(\"Mean\", variable)], \n       aes(x=rn, y=value, label = round(value, 1))) + \n  geom_lollipop(point.size = 4, point.colour = \"orange3\", pch = 19, bg = 2) +\n  geom_text(aes(nudge_y = 2), hjust = -.3) +\n  coord_flip() +\n  #facet_wrap(~variable) +\n  theme_minimal() +\n  labs(y=\"MeanDecreaseGini\", x=NULL, \n  title = \"Feature Importance Plot from Cardio Vascular Dataset\", cex = 0.9) +\n  expand_limits(y = 1300) + theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n\nWarning in geom_text(aes(nudge_y = 2), hjust = -0.3): Ignoring unknown\naesthetics: nudge_y\n\n\nWarning: Using the `size` aesthetic with geom_segment was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead."
  },
  {
    "objectID": "ProjectCode.html#we-will-select-only-20000-participants-in-our-analysis.",
    "href": "ProjectCode.html#we-will-select-only-20000-participants-in-our-analysis.",
    "title": "All Code——Random forest model",
    "section": "We will select only 20000 participants in our analysis.",
    "text": "We will select only 20000 participants in our analysis.\n\nNumber_ofparticipants &lt;- 10000\n## This is a very large dataset, let's only select 10000 samples from both groups\nset.seed(150)\nYes_case &lt;- sample(which(Heart_data$Heart_Disease == \"Yes\"), Number_ofparticipants)\nset.seed(150)\nNo_case &lt;- sample(which(Heart_data$Heart_Disease == \"No\"), Number_ofparticipants)\nData_yes &lt;- Heart_data[Yes_case, ]\nData_no &lt;-  Heart_data[No_case, ]\nData_total &lt;- rbind(Data_yes, Data_no)\nhead(Data_total)\n\n       General_Health              Checkup Exercise Heart_Disease Skin_Cancer\n43289            Poor Within the past year      Yes           Yes         Yes\n281436           Fair Within the past year      Yes           Yes          No\n196610           Fair Within the past year      Yes           Yes          No\n306903           Fair Within the past year       No           Yes          No\n304887           Poor Within the past year       No           Yes          No\n278988           Fair Within the past year      Yes           Yes          No\n       Other_Cancer Depression Diabetes Arthritis    Sex Age_Category\n43289            No         No      Yes       Yes   Male        65-69\n281436           No         No      Yes       Yes   Male        70-74\n196610           No         No      Yes       Yes Female        40-44\n306903          Yes         No      Yes       Yes Female        55-59\n304887           No        Yes       No       Yes   Male          80+\n278988           No         No       No        No   Male        50-54\n       Height_.cm. Weight_.kg.   BMI Smoking_History Alcohol_Consumption\n43289          175      102.97 33.52             Yes                   0\n281436         170      104.33 36.02             Yes                   0\n196610         180      136.08 41.84             Yes                   5\n306903         160       65.77 25.69              No                   0\n304887         155       62.60 26.07             Yes                   0\n278988         180      106.59 32.78              No                  25\n       Fruit_Consumption Green_Vegetables_Consumption FriedPotato_Consumption\n43289                 12                           16                       3\n281436                60                           30                       4\n196610                60                            2                      12\n306903                12                           12                       3\n304887                28                           28                       4\n278988                 3                            4                       8"
  },
  {
    "objectID": "Lab01.html",
    "href": "Lab01.html",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"has_annotations\" \"x\"               \"y\"              \n\nrm(x,y) # Remove objects\nls()\n\n[1] \"has_annotations\"\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9956628\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "Lab01.html#left-arrow-vs-right-arrow",
    "href": "Lab01.html#left-arrow-vs-right-arrow",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)"
  },
  {
    "objectID": "Lab01.html#using-function",
    "href": "Lab01.html#using-function",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "length(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3"
  },
  {
    "objectID": "Lab01.html#using---operators",
    "href": "Lab01.html#using---operators",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"has_annotations\" \"x\"               \"y\"              \n\nrm(x,y) # Remove objects\nls()\n\n[1] \"has_annotations\"\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!"
  },
  {
    "objectID": "Lab01.html#matrix-operations",
    "href": "Lab01.html#matrix-operations",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9956628\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)"
  },
  {
    "objectID": "Lab01.html#simple-descriptive-statistics-base",
    "href": "Lab01.html#simple-descriptive-statistics-base",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "mean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768"
  },
  {
    "objectID": "Lab01.html#visualization-using-r-graphics-without-packages",
    "href": "Lab01.html#visualization-using-r-graphics-without-packages",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "Lab03.html",
    "href": "Lab03.html",
    "title": "EPPS 6323: Lab03 R programming (Exploratory Data Analysis)",
    "section": "",
    "text": "library(haven)\nTEDS_2016 &lt;- \nread_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")"
  },
  {
    "objectID": "Lab03.html#loading-necessary-packages-and-the-data",
    "href": "Lab03.html#loading-necessary-packages-and-the-data",
    "title": "EPPS 6323: Lab03 R programming (Exploratory Data Analysis)",
    "section": "",
    "text": "library(haven)\nTEDS_2016 &lt;- \nread_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")"
  }
]